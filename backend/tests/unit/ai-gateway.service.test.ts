/**
 * AI GatewayæœåŠ¡å•å…ƒæµ‹è¯•
 * è‰¹ï¼Œè¿™ä¸ªæµ‹è¯•æ–‡ä»¶è¦†ç›–AI Gatewayçš„æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½ï¼
 */

import axios from 'axios';
import { EventEmitter } from 'events';
import { aiGateway } from '../../src/services/ai-gateway.service.js';
import * as providerEndpointsRepo from '../../src/repositories/providerEndpoints.repo.js';
import logger from '../../src/utils/logger.js';

// Mockä¾èµ–
jest.mock('axios');
jest.mock('../../src/repositories/providerEndpoints.repo.js', () => ({
  // ğŸŸ¢ å·²ä¿®å¤ï¼šä½¿ç”¨å®é™…repoå¯¼å‡ºçš„å‡½æ•°åï¼
  getProviderEndpoint: jest.fn(),
  listProviderEndpoints: jest.fn(),
  createProviderEndpoint: jest.fn(),
  updateProviderEndpoint: jest.fn(),
  deleteProviderEndpoint: jest.fn()
}));
jest.mock('../../src/utils/logger.js');

const mockedAxios = axios as jest.Mocked<typeof axios>;
// ğŸŸ¢ å·²ä¿®å¤ï¼šMockå‡½æ•°ååŒ¹é…å®é™…repoå¯¼å‡ºï¼
const mockedProviderRepo = (providerEndpointsRepo as any) as {
  getProviderEndpoint: jest.MockedFunction<any>;
  listProviderEndpoints: jest.MockedFunction<any>;
  createProviderEndpoint: jest.MockedFunction<any>;
  updateProviderEndpoint: jest.MockedFunction<any>;
  deleteProviderEndpoint: jest.MockedFunction<any>;
};
const mockedLogger = logger as jest.Mocked<typeof logger>;

// ğŸŸ¢ å·²ä¿®å¤ï¼šMockå‡½æ•°ååŒ¹é…å®é™…repoï¼Œç§»é™¤skip
describe('AIGatewayService', () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

  describe('chat() - éæµå¼èŠå¤©', () => {
    it('åº”è¯¥æˆåŠŸè°ƒç”¨OpenAI Provider', async () => {
      // Arrange
      const mockProvider = {
        provider_ref: 'openai-1',
        provider_name: 'OpenAI GPT-4',
        endpoint_url: 'https://api.openai.com/v1/chat/completions',
        auth_type: 'bearer',
        credentials_encrypted: {
          api_key: 'sk-test123'
        },
        weight: 100,
        timeout_ms: 30000
      };

      const mockRequest = {
        model: 'gpt-4',
        messages: [{ role: 'user' as const, content: 'ä½ å¥½' }],
        temperature: 0.7
      };

      const mockResponse = {
        data: {
          id: 'chatcmpl-123',
          object: 'chat.completion',
          created: 1234567890,
          model: 'gpt-4',
          choices: [
            {
              index: 0,
              message: {
                role: 'assistant',
                content: 'ä½ å¥½ï¼æˆ‘èƒ½å¸®ä½ ä»€ä¹ˆï¼Ÿ'
              },
              finish_reason: 'stop'
            }
          ],
          usage: {
            prompt_tokens: 10,
            completion_tokens: 15,
            total_tokens: 25
          }
        }
      };

      mockedProviderRepo.getProviderEndpoint.mockResolvedValue(mockProvider);
      mockedAxios.post.mockResolvedValue(mockResponse);

      // Act
      const result = await aiGateway.chat(mockRequest, 'openai-1');

      // Assert
      expect(result).toEqual(mockResponse.data);
      expect(mockedProviderRepo.getProviderEndpoint).toHaveBeenCalledWith('openai-1');
      expect(mockedAxios.post).toHaveBeenCalledWith(
        mockProvider.endpoint_url,
        expect.objectContaining({
          model: 'gpt-4',
          messages: mockRequest.messages,
          temperature: 0.7
        }),
        expect.objectContaining({
          headers: expect.objectContaining({
            'Content-Type': 'application/json',
            Authorization: 'Bearer sk-test123'
          })
        })
      );
      expect(mockedLogger.info).toHaveBeenCalledWith(
        expect.stringContaining('[AIGateway] Chatå“åº”æˆåŠŸ')
      );
    });

    it('åº”è¯¥æˆåŠŸè°ƒç”¨Anthropic Providerå¹¶é€‚é…å“åº”æ ¼å¼', async () => {
      // Arrange
      const mockProvider = {
        provider_ref: 'anthropic-1',
        provider_name: 'Anthropic Claude',
        endpoint_url: 'https://api.anthropic.com/v1/messages',
        auth_type: 'bearer',
        credentials_encrypted: {
          api_key: 'sk-ant-test'
        },
        weight: 100,
        timeout_ms: 30000
      };

      const mockRequest = {
        model: 'claude-3-opus',
        messages: [{ role: 'user' as const, content: 'Hello' }],
        max_tokens: 1024
      };

      const mockAnthropicResponse = {
        data: {
          id: 'msg_123',
          model: 'claude-3-opus',
          content: [{ type: 'text', text: 'Hello! How can I help you?' }],
          stop_reason: 'end_turn',
          usage: {
            input_tokens: 5,
            output_tokens: 8
          }
        }
      };

      mockedProviderRepo.getProviderEndpoint.mockResolvedValue(mockProvider);
      mockedAxios.post.mockResolvedValue(mockAnthropicResponse);

      // Act
      const result = await aiGateway.chat(mockRequest, 'anthropic-1');

      // Assert
      expect(result.object).toBe('chat.completion');
      expect(result.choices[0].message?.content).toBe('Hello! How can I help you?');
      expect(result.usage?.total_tokens).toBe(13); // 5 + 8
      expect(mockedAxios.post).toHaveBeenCalledWith(
        mockProvider.endpoint_url,
        expect.objectContaining({
          model: 'claude-3-opus',
          max_tokens: 1024,
          messages: expect.arrayContaining([
            expect.objectContaining({
              role: 'user',
              content: 'Hello'
            })
          ])
        }),
        expect.any(Object)
      );
    });

    it('åº”è¯¥è‡ªåŠ¨é€‰æ‹©Providerï¼ˆè´Ÿè½½å‡è¡¡ï¼‰', async () => {
      // Arrange
      const mockProviders = [
        {
          provider_ref: 'openai-1',
          provider_name: 'OpenAI GPT-4',
          endpoint_url: 'https://api.openai.com/v1/chat/completions',
          auth_type: 'bearer',
          credentials_encrypted: { api_key: 'sk-1' },
          weight: 100,
          timeout_ms: 30000
        },
        {
          provider_ref: 'openai-2',
          provider_name: 'OpenAI GPT-4',
          endpoint_url: 'https://api.openai.com/v1/chat/completions',
          auth_type: 'bearer',
          credentials_encrypted: { api_key: 'sk-2' },
          weight: 50,
          timeout_ms: 30000
        }
      ];

      const mockRequest = {
        model: 'gpt-4',
        messages: [{ role: 'user' as const, content: 'Test' }]
      };

      const mockResponse = {
        data: {
          id: 'test',
          object: 'chat.completion',
          created: 123,
          model: 'gpt-4',
          choices: [
            {
              index: 0,
              message: { role: 'assistant', content: 'Response' },
              finish_reason: 'stop'
            }
          ]
        }
      };

      mockedProviderRepo.listProviderEndpoints.mockResolvedValue(mockProviders);
      mockedAxios.post.mockResolvedValue(mockResponse);

      // Act
      const result = await aiGateway.chat(mockRequest); // ä¸æŒ‡å®šproviderRef

      // Assert
      expect(mockedProviderRepo.listProviderEndpoints).toHaveBeenCalledWith({});
      expect(mockedAxios.post).toHaveBeenCalled();
      expect(result).toEqual(mockResponse.data);
    });

    it('åº”è¯¥åœ¨Providerä¸å­˜åœ¨æ—¶æŠ›å‡ºé”™è¯¯', async () => {
      // Arrange
      mockedProviderRepo.getProviderEndpoint.mockResolvedValue(null);

      const mockRequest = {
        model: 'gpt-4',
        messages: [{ role: 'user' as const, content: 'Test' }]
      };

      // Act & Assert
      await expect(aiGateway.chat(mockRequest, 'non-existent')).rejects.toThrow(
        'Provider not found: non-existent'
      );
    });

    it('åº”è¯¥åœ¨APIè°ƒç”¨å¤±è´¥æ—¶æŠ›å‡ºé”™è¯¯', async () => {
      // Arrange
      const mockProvider = {
        provider_ref: 'openai-1',
        provider_name: 'OpenAI GPT-4',
        endpoint_url: 'https://api.openai.com/v1/chat/completions',
        auth_type: 'bearer',
        credentials_encrypted: { api_key: 'sk-test' },
        weight: 100,
        timeout_ms: 30000
      };

      const mockRequest = {
        model: 'gpt-4',
        messages: [{ role: 'user' as const, content: 'Test' }]
      };

      mockedProviderRepo.getProviderEndpoint.mockResolvedValue(mockProvider);
      mockedAxios.post.mockRejectedValue(new Error('Network error'));

      // Act & Assert
      await expect(aiGateway.chat(mockRequest, 'openai-1')).rejects.toThrow(
        'Chat failed: Network error'
      );

      expect(mockedLogger.error).toHaveBeenCalledWith(
        '[AIGateway] Chatè¯·æ±‚å¤±è´¥:',
        expect.any(Error)
      );
    });
  });

  describe('chatStream() - æµå¼èŠå¤©', () => {
    it('åº”è¯¥æˆåŠŸè¿”å›SSEæµå¼EventEmitter', async () => {
      // Arrange
      const mockProvider = {
        provider_ref: 'openai-1',
        provider_name: 'OpenAI GPT-4',
        endpoint_url: 'https://api.openai.com/v1/chat/completions',
        auth_type: 'bearer',
        credentials_encrypted: { api_key: 'sk-test' },
        weight: 100,
        timeout_ms: 60000
      };

      const mockRequest = {
        model: 'gpt-4',
        messages: [{ role: 'user' as const, content: 'Hello' }],
        stream: true
      };

      // æ¨¡æ‹Ÿæµå¼å“åº”
      const mockStream = new EventEmitter();
      const mockResponse = {
        data: mockStream
      };

      mockedProviderRepo.getProviderEndpoint.mockResolvedValue(mockProvider);
      mockedAxios.post.mockResolvedValue(mockResponse);

      // Act
      const emitter = await aiGateway.chatStream(mockRequest, 'openai-1');

      // Assert
      expect(emitter).toBeInstanceOf(EventEmitter);
      expect(mockedProviderRepo.getProviderEndpoint).toHaveBeenCalledWith('openai-1');
      expect(mockedAxios.post).toHaveBeenCalledWith(
        mockProvider.endpoint_url,
        expect.objectContaining({ stream: true }),
        expect.objectContaining({
          responseType: 'stream'
        })
      );
    });

    it('åº”è¯¥æ­£ç¡®è§£æOpenAIæµå¼chunks', async () => {
      // Arrange
      const mockProvider = {
        provider_ref: 'openai-1',
        provider_name: 'OpenAI GPT-4',
        endpoint_url: 'https://api.openai.com/v1/chat/completions',
        auth_type: 'bearer',
        credentials_encrypted: { api_key: 'sk-test' },
        weight: 100,
        timeout_ms: 60000
      };

      const mockRequest = {
        model: 'gpt-4',
        messages: [{ role: 'user' as const, content: 'Hello' }],
        stream: true
      };

      const mockStream = new EventEmitter();
      const mockResponse = { data: mockStream };

      mockedProviderRepo.getProviderEndpoint.mockResolvedValue(mockProvider);
      mockedAxios.post.mockResolvedValue(mockResponse);

      // Act
      const emitter = await aiGateway.chatStream(mockRequest, 'openai-1');

      const receivedChunks: any[] = [];
      emitter.on('data', (chunk) => receivedChunks.push(chunk));

      // æ¨¡æ‹Ÿæµå¼æ•°æ®
      const chunk1 = {
        id: 'chatcmpl-123',
        object: 'chat.completion.chunk',
        created: 123,
        model: 'gpt-4',
        choices: [
          {
            index: 0,
            delta: { role: 'assistant', content: 'Hello' },
            finish_reason: null
          }
        ]
      };

      const chunk2 = {
        id: 'chatcmpl-123',
        object: 'chat.completion.chunk',
        created: 123,
        model: 'gpt-4',
        choices: [
          {
            index: 0,
            delta: { content: ' there!' },
            finish_reason: null
          }
        ]
      };

      // ç­‰å¾…å¼‚æ­¥åˆå§‹åŒ–å®Œæˆ
      await new Promise((resolve) => setTimeout(resolve, 100));

      mockStream.emit('data', Buffer.from(`data: ${JSON.stringify(chunk1)}\n\n`));
      mockStream.emit('data', Buffer.from(`data: ${JSON.stringify(chunk2)}\n\n`));
      mockStream.emit('data', Buffer.from('data: [DONE]\n\n'));
      mockStream.emit('end');

      // ç­‰å¾…æ‰€æœ‰äº‹ä»¶å¤„ç†å®Œæˆ
      await new Promise((resolve) => setTimeout(resolve, 100));

      // Assert
      expect(receivedChunks.length).toBeGreaterThanOrEqual(2);
      expect(receivedChunks[0]).toMatchObject({
        object: 'chat.completion.chunk',
        choices: expect.arrayContaining([
          expect.objectContaining({
            delta: expect.objectContaining({ content: 'Hello' })
          })
        ])
      });
    });

    it('åº”è¯¥åœ¨Providerä¸å­˜åœ¨æ—¶è§¦å‘erroräº‹ä»¶', async () => {
      // Arrange
      // ğŸŸ¢ ä¿®å¤ï¼šæ·»åŠ å»¶è¿Ÿç¡®ä¿emitterå…ˆè¿”å›å†emit error
      mockedProviderRepo.getProviderEndpoint.mockImplementation(
        () => new Promise((resolve) => setTimeout(() => resolve(null), 10))
      );

      const mockRequest = {
        model: 'gpt-4',
        messages: [{ role: 'user' as const, content: 'Test' }]
      };

      // Act
      const emitter = await aiGateway.chatStream(mockRequest, 'non-existent');

      // Assert
      const errorPromise = new Promise<any>((resolve, reject) => {
        emitter.on('error', resolve);
        setTimeout(() => reject(new Error('Timeout waiting for error')), 500);
      });

      const error = await errorPromise;
      expect(error).toEqual(
        expect.objectContaining({
          message: 'Provider not found: non-existent'
        })
      );
    });
  });

  describe('é€‚é…å™¨æµ‹è¯•', () => {
    it('OpenAIAdapteråº”è¯¥æ­£ç¡®é€‚é…è¯·æ±‚å’Œå“åº”', async () => {
      // Arrange
      const mockProvider = {
        provider_ref: 'openai-1',
        provider_name: 'OpenAI GPT-4',
        endpoint_url: 'https://api.openai.com/v1/chat/completions',
        auth_type: 'bearer',
        credentials_encrypted: { api_key: 'sk-test' },
        weight: 100,
        timeout_ms: 30000
      };

      const mockRequest = {
        model: 'gpt-4',
        messages: [{ role: 'user' as const, content: 'Test' }],
        temperature: 0.8,
        max_tokens: 100,
        tools: [
          {
            type: 'function',
            function: { name: 'get_weather', description: 'Get weather' }
          }
        ]
      };

      const mockResponse = {
        data: {
          id: 'test',
          object: 'chat.completion',
          created: 123,
          model: 'gpt-4',
          choices: [
            {
              index: 0,
              message: { role: 'assistant', content: 'Response' },
              finish_reason: 'stop'
            }
          ]
        }
      };

      mockedProviderRepo.getProviderEndpoint.mockResolvedValue(mockProvider);
      mockedAxios.post.mockResolvedValue(mockResponse);

      // Act
      const result = await aiGateway.chat(mockRequest, 'openai-1');

      // Assert - è¯·æ±‚åº”è¯¥åŒ…å«toolså‚æ•°
      expect(mockedAxios.post).toHaveBeenCalledWith(
        expect.any(String),
        expect.objectContaining({
          tools: mockRequest.tools,
          temperature: 0.8,
          max_tokens: 100
        }),
        expect.any(Object)
      );

      // å“åº”åº”è¯¥ä¿æŒOpenAIæ ¼å¼
      expect(result).toEqual(mockResponse.data);
    });

    it('AnthropicAdapteråº”è¯¥æ­£ç¡®è½¬æ¢æ¶ˆæ¯æ ¼å¼', async () => {
      // Arrange
      const mockProvider = {
        provider_ref: 'anthropic-1',
        provider_name: 'Anthropic Claude',
        endpoint_url: 'https://api.anthropic.com/v1/messages',
        auth_type: 'bearer',
        credentials_encrypted: { api_key: 'sk-ant-test' },
        weight: 100,
        timeout_ms: 30000
      };

      const mockRequest = {
        model: 'claude-3-opus',
        messages: [
          { role: 'system' as const, content: 'You are helpful' },
          { role: 'user' as const, content: 'Hello' }
        ]
      };

      const mockResponse = {
        data: {
          id: 'msg_123',
          model: 'claude-3-opus',
          content: [{ type: 'text', text: 'Hi!' }],
          stop_reason: 'end_turn',
          usage: { input_tokens: 10, output_tokens: 5 }
        }
      };

      mockedProviderRepo.getProviderEndpoint.mockResolvedValue(mockProvider);
      mockedAxios.post.mockResolvedValue(mockResponse);

      // Act
      await aiGateway.chat(mockRequest, 'anthropic-1');

      // Assert - systemæ¶ˆæ¯åº”è¯¥è½¬æ¢ä¸ºuseræ¶ˆæ¯
      expect(mockedAxios.post).toHaveBeenCalledWith(
        expect.any(String),
        expect.objectContaining({
          messages: expect.arrayContaining([
            expect.objectContaining({
              role: 'user', // systemè½¬user
              content: 'You are helpful'
            }),
            expect.objectContaining({
              role: 'user',
              content: 'Hello'
            })
          ])
        }),
        expect.any(Object)
      );
    });
  });
});
